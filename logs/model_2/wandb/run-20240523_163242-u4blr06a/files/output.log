
Epoch 01 | train:   0%|                                                                                                                              | 0/139 [00:00<?, ?batch/s]
image shape torch.Size([256, 3, 256, 256])
image shape after unsqueeze torch.Size([256, 3, 256, 256])
resized image shape  torch.Size([256, 3, 224, 224])
outputs shape  torch.Size([256, 384])
cls token shape  torch.Size([384])
Traceback (most recent call last):
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 82, in <module>
    main(args=args, config=config)
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 70, in main
    trainer.train(train_dataloader=train_dataloader,
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 25, in train
    self.run_epoch(dataloader=train_dataloader, epoch=epoch, phase='train')
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 42, in run_epoch
    output = self.model(image, caption_indices[:, :-1])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/base.py", line 37, in forward
    output = self.caption_generator.forward(encoded_image=encoded_image, caption_indices=caption_indices)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/model_2.py", line 137, in forward
    embeddings = self._get_embeddings(encoded_image=encoded_image, caption_indices=caption_indices)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/model_2.py", line 116, in _get_embeddings
    embeddings, _ = pack([encoded_image, embeddings], 'batch * embedding_dim')
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/einops/packing.py", line 80, in pack
    raise EinopsError(f'packed tensor #{i} (enumeration starts with 0) has shape {shape}, '
einops.EinopsError: packed tensor #0 (enumeration starts with 0) has shape torch.Size([128]), while pattern batch * embedding_dim assumes at least 2 axes