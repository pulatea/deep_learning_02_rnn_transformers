
Epoch 01 | train:   0%|                                                                                                                              | 0/139 [00:00<?, ?batch/s]
attention weights shape  torch.Size([256, 1, 25])
output shape  torch.Size([256, 25, 128])
Traceback (most recent call last):
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 82, in <module>
    main(args=args, config=config)
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 70, in main
    trainer.train(train_dataloader=train_dataloader,
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 25, in train
    self.run_epoch(dataloader=train_dataloader, epoch=epoch, phase='train')
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 42, in run_epoch
    output = self.model(image, caption_indices[:, :-1])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/base.py", line 37, in forward
    output = self.caption_generator.forward(encoded_image=encoded_image, caption_indices=caption_indices)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/model_4.py", line 148, in forward
    output = torch.cat((output, context), 2)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 2. Expected size 25 but got size 1 for tensor number 1 in the list.