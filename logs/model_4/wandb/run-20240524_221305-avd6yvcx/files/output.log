
Epoch 01 | train:   0%|                                | 0/139 [00:00<?, ?batch/s]
embeddings shape  torch.Size([256, 28, 128])
context_vector shape  torch.Size([256])
Traceback (most recent call last):
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 82, in <module>
    main(args=args, config=config)
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 70, in main
    trainer.train(train_dataloader=train_dataloader,
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 25, in train
    self.run_epoch(dataloader=train_dataloader, epoch=epoch, phase='train')
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 42, in run_epoch
    output = self.model(image, caption_indices[:, :-1])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/base.py", line 37, in forward
    output = self.caption_generator.forward(encoded_image=encoded_image, caption_indices=caption_indices)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/model_4.py", line 145, in forward
    rnn_input = torch.cat((unsqueezed_embeddings, context_vector), dim=3)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: Dimension out of range (expected to be in range of [-3, 2], but got 3)