
Epoch 01 | train:   0%|                                                                                                                              | 0/139 [00:00<?, ?batch/s]
attention weights shape  tensor([[[0.0409, 0.0407, 0.0406,  ..., 0.0377, 0.0378, 0.0377]],
        [[0.0405, 0.0407, 0.0411,  ..., 0.0383, 0.0384, 0.0381]],
        [[0.0405, 0.0413, 0.0412,  ..., 0.0379, 0.0380, 0.0380]],
        ...,
        [[0.0417, 0.0424, 0.0415,  ..., 0.0381, 0.0385, 0.0388]],
        [[0.0408, 0.0407, 0.0403,  ..., 0.0383, 0.0384, 0.0382]],
        [[0.0415, 0.0415, 0.0421,  ..., 0.0384, 0.0388, 0.0386]]],
       grad_fn=<SoftmaxBackward0>)
output shape  torch.Size([256, 25, 128])
Traceback (most recent call last):
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 82, in <module>
    main(args=args, config=config)
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/train.py", line 70, in main
    trainer.train(train_dataloader=train_dataloader,
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 25, in train
    self.run_epoch(dataloader=train_dataloader, epoch=epoch, phase='train')
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/training/trainer.py", line 42, in run_epoch
    output = self.model(image, caption_indices[:, :-1])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/base.py", line 37, in forward
    output = self.caption_generator.forward(encoded_image=encoded_image, caption_indices=caption_indices)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/teapula/Documents/AIM/Deep_Learning/assignment_2/models/model_4.py", line 148, in forward
    output = torch.cat((output, context), 2)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 2. Expected size 25 but got size 1 for tensor number 1 in the list.